{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"./data/2021.csv\")\n",
    "\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "df = df[[\"Country\", \"EdLevel\", \"YearsCodePro\", \"Employment\", \"ConvertedCompYearly\" , \"Gender\" , \"DevType\" , \"OrgSize\" , \"Age1stCode\",\"LearnCode\",\"YearsCode\",\"LanguageHaveWorkedWith\" , \"DatabaseHaveWorkedWith\" , \"PlatformHaveWorkedWith\" , \"OpSys\"]]\n",
    "df = df.rename({\"ConvertedCompYearly\": \"Salary\"}, axis=1)\n",
    "\n",
    "def shorten_categories(categories, cutoff):\n",
    "    categorical_map = {}\n",
    "    for i in range(len(categories)):\n",
    "        if categories.values[i] >= cutoff:\n",
    "            categorical_map[categories.index[i]] = categories.index[i]\n",
    "        else:\n",
    "            categorical_map[categories.index[i]] = 'Other'\n",
    "    return categorical_map\n",
    "\n",
    "def clean_organization(x):\n",
    "    if '2 to 9 employees' in x or '10 to 19 employees' in x or 'Fewer than 10 employees' in x:\n",
    "        return 'Micro'\n",
    "    if '100 to 499 employees' in x or '20 to 99 employees' in x :\n",
    "        return 'Small'\n",
    "    if '500 to 999 employees' in x  :\n",
    "        return 'Medium'\n",
    "    if '1,000 to 4,999 employees' in x:\n",
    "        return 'Large'\n",
    "    if '10,000 or more employees' in x or '5,000 to 9,999 employees' in x:\n",
    "        return 'Enterprise'\n",
    "    return 'Self Employed'\n",
    "\n",
    "df = df[df[\"OrgSize\"].notnull()]\n",
    "df['OrgSize'] = df['OrgSize'].apply(clean_organization) \n",
    "df['OrgSize'].value_counts()\n",
    "\n",
    "df = df.loc[df['Gender'].isin(['Man' , 'Woman'])]\n",
    "\n",
    "country_map = shorten_categories(df.DevType.value_counts(), 200)\n",
    "df[\"DevType\"] = df[\"DevType\"].map(country_map)\n",
    "df['DevType'] = df['DevType'].str.split(';')\n",
    "df = df.explode('DevType')\n",
    "df = df[df[\"DevType\"].notnull()]\n",
    "\n",
    "def clean_types(x):\n",
    "    if 'Developer, full-stack'  in x :\n",
    "        return 'Full Stack Developer'\n",
    "    if 'Developer, back-end' in x  :\n",
    "        return 'Back-End Developer'\n",
    "    if 'Developer, front-end' in x :\n",
    "        return 'Front-End Developer'\n",
    "    if 'Developer, mobile' in x:\n",
    "        return 'Mobile Developer'\n",
    "    return x\n",
    "\n",
    "df['DevType'] = df['DevType'].apply(clean_types)\n",
    "df = df[df[\"DevType\"] != \"Other\"]\n",
    "df = df[df[\"DevType\"] != \"Other (please specify):\"]\n",
    "df['DevType'].value_counts()\n",
    "\n",
    "def clean_experience(x):\n",
    "    if x ==  'More than 50 years':\n",
    "        return 50\n",
    "    if x == 'Less than 1 year':\n",
    "        return 0.5\n",
    "    return float(x)\n",
    "\n",
    "df['YearsCodePro'] = df['YearsCodePro'].apply(clean_experience)\n",
    "\n",
    "def clean_education(x):\n",
    "    if 'Bachelor’s degree' in x:\n",
    "        return 'Bachelor’s degree'\n",
    "    if 'Master’s degree' in x:\n",
    "        return 'Master’s degree'\n",
    "    if 'Professional degree' in x or 'Other doctoral' in x:\n",
    "        return 'Post grad'\n",
    "    return 'Less than a Bachelors'\n",
    "\n",
    "df = df[df[\"EdLevel\"].notnull()]\n",
    "df['EdLevel'] = df['EdLevel'].apply(clean_education)\n",
    "df['EdLevel'].value_counts()\n",
    "\n",
    "df = df[df[\"Age1stCode\"].notnull()]\n",
    "df['Age1stCode'].value_counts()\n",
    "\n",
    "def clean_learn_code(x): \n",
    "    if 'Books / Physical media' in x : \n",
    "        return 'Books'\n",
    "    \n",
    "    if 'Other online resources (ex: videos, blogs, etc)' in x :\n",
    "        return 'Online resources (Videos , blogs)'\n",
    "    return x\n",
    "\n",
    "learn_code_map = shorten_categories(df.LearnCode.value_counts(), 100)\n",
    "df[\"LearnCode\"] = df[\"LearnCode\"].map(learn_code_map)\n",
    "df['LearnCode'] = df['LearnCode'].str.split(';')\n",
    "df = df.explode('LearnCode')\n",
    "df = df[df[\"LearnCode\"].notnull()]\n",
    "df = df[df['LearnCode'] != 'Other']\n",
    "df = df[df['LearnCode'] != 'Other (please specify):']\n",
    "df['LearnCode'] = df['LearnCode'].apply(clean_learn_code)\n",
    "df[\"LearnCode\"].value_counts()\n",
    "\n",
    "def clean_years_coding(x):\n",
    "    if x ==  'More than 50 years':\n",
    "        return 50\n",
    "    if x == 'Less than 1 year':\n",
    "        return 0.5\n",
    "    return float(x)\n",
    "\n",
    "df['YearsCode'] = df['YearsCode'].apply(clean_years_coding)\n",
    "df = df[df[\"YearsCode\"].notnull()]\n",
    "\n",
    "program_lang_map = shorten_categories(df.LanguageHaveWorkedWith.value_counts(), 500)\n",
    "df[\"LanguageHaveWorkedWith\"] = df[\"LanguageHaveWorkedWith\"].map(program_lang_map)\n",
    "df['LanguageHaveWorkedWith'] = df['LanguageHaveWorkedWith'].str.split(';')\n",
    "df = df.explode('LanguageHaveWorkedWith')\n",
    "df = df[df[\"LanguageHaveWorkedWith\"].notnull()]\n",
    "df = df[df['LanguageHaveWorkedWith'] != 'Other']\n",
    "df[\"LanguageHaveWorkedWith\"].value_counts()\n",
    "\n",
    "database_lang_map = shorten_categories(df.DatabaseHaveWorkedWith.value_counts(), 1000)\n",
    "df[\"DatabaseHaveWorkedWith\"] = df[\"DatabaseHaveWorkedWith\"].map(database_lang_map)\n",
    "df['DatabaseHaveWorkedWith'] = df['DatabaseHaveWorkedWith'].str.split(';')\n",
    "df = df.explode('DatabaseHaveWorkedWith')\n",
    "df = df[df[\"DatabaseHaveWorkedWith\"].notnull()]\n",
    "df = df[df['DatabaseHaveWorkedWith'] != 'Other']\n",
    "df[\"DatabaseHaveWorkedWith\"].value_counts()\n",
    "\n",
    "platform_lang_map = shorten_categories(df.PlatformHaveWorkedWith.value_counts(), 500)\n",
    "df[\"PlatformHaveWorkedWith\"] = df[\"PlatformHaveWorkedWith\"].map(platform_lang_map)\n",
    "df['PlatformHaveWorkedWith'] = df['PlatformHaveWorkedWith'].str.split(';')\n",
    "df = df.explode('PlatformHaveWorkedWith')\n",
    "df = df[df[\"PlatformHaveWorkedWith\"].notnull()]\n",
    "df = df[df['PlatformHaveWorkedWith'] != 'Other']\n",
    "df[\"PlatformHaveWorkedWith\"].value_counts()\n",
    "\n",
    "ops_map = shorten_categories(df.OpSys.value_counts(), 50)\n",
    "df[\"OpSys\"] = df[\"OpSys\"].map(ops_map)\n",
    "# df['OpSys'] = df['OpSys'].str.split(';')\n",
    "# df = df.explode('OpSys')\n",
    "df = df[df[\"OpSys\"].notnull()]\n",
    "df = df[df['OpSys'] != 'Other']\n",
    "df = df[df['OpSys'] != 'Other (please specify):']\n",
    "df[\"OpSys\"].value_counts()\n",
    "\n",
    "df = df[df[\"Salary\"].notnull()]\n",
    "\n",
    "df = df.dropna()\n",
    "df.isnull().sum()\n",
    "\n",
    "df = df[df[\"Employment\"] == \"Employed full-time\"]\n",
    "df = df.drop(\"Employment\", axis=1)\n",
    "\n",
    "country_map = shorten_categories(df.Country.value_counts(), 200)\n",
    "df['Country'] = df['Country'].map(country_map)\n",
    "\n",
    "df = df[df[\"Salary\"] <= 250000]\n",
    "df = df[df[\"Salary\"] >= 10000]\n",
    "df = df[df['Country'] != 'Other']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_education = LabelEncoder()\n",
    "df['EdLevel'] = le_education.fit_transform(df['EdLevel'])\n",
    "df[\"EdLevel\"].unique()\n",
    "\n",
    "le_gender = LabelEncoder()\n",
    "df['Gender'] = le_gender.fit_transform(df['Gender'])\n",
    "\n",
    "le_devtype = LabelEncoder()\n",
    "df['DevType'] = le_devtype.fit_transform(df['DevType'])\n",
    "\n",
    "le_country = LabelEncoder()\n",
    "df['Country'] = le_country.fit_transform(df['Country'])\n",
    "\n",
    "le_orgsize = LabelEncoder()\n",
    "df['OrgSize'] = le_orgsize.fit_transform(df['OrgSize'])\n",
    "\n",
    "le_Age1stCode = LabelEncoder()\n",
    "df['Age1stCode'] = le_Age1stCode.fit_transform(df['Age1stCode'])\n",
    "\n",
    "le_LearnCode = LabelEncoder()\n",
    "df['LearnCode'] = le_LearnCode.fit_transform(df['LearnCode'])\n",
    "\n",
    "le_YearsCode = LabelEncoder()\n",
    "df['YearsCode'] = le_YearsCode.fit_transform(df['YearsCode'])\n",
    "\n",
    "le_LanguageHaveWorkedWith = LabelEncoder()\n",
    "df['LanguageHaveWorkedWith'] = le_LanguageHaveWorkedWith.fit_transform(df['LanguageHaveWorkedWith'])\n",
    "\n",
    "le_DatabaseHaveWorkedWith = LabelEncoder()\n",
    "df['DatabaseHaveWorkedWith'] = le_DatabaseHaveWorkedWith.fit_transform(df['DatabaseHaveWorkedWith'])\n",
    "\n",
    "le_PlatformHaveWorkedWith = LabelEncoder()\n",
    "df['PlatformHaveWorkedWith'] = le_PlatformHaveWorkedWith.fit_transform(df['PlatformHaveWorkedWith'])\n",
    "\n",
    "le_OpSys = LabelEncoder()\n",
    "df['OpSys'] = le_OpSys.fit_transform(df['OpSys'])\n",
    "\n",
    "X = df.drop(\"Salary\", axis=1)\n",
    "y = df[\"Salary\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train , y_test = train_test_split(X, y, test_size=0.2 , random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  r2_score, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2-score: 0.428817\n",
      "Mean absolute error: 23635.676371\n",
      "Mean squared error: 30674.691306\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linear_reg = LinearRegression()\n",
    "# linear_reg.fit(X_train, y_train)\n",
    "linear_reg.fit(X_train, y_train)\n",
    "# y_pred = linear_reg.predict(X_test)\n",
    "y_pred = linear_reg.predict(X_test)\n",
    "\n",
    "linear_reg_r2_score = r2_score(y_test, y_pred)\n",
    "linear_reg_ab_error = mean_absolute_error(y_test, y_pred)\n",
    "linear_reg_sqrt_error = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"r2-score: %2f\" % (linear_reg_r2_score))\n",
    "print(\"Mean absolute error: %2f\" % (linear_reg_ab_error))\n",
    "print(\"Mean squared error: %2f\" % (linear_reg_sqrt_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DECISION TREE REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dec_tree_reg = DecisionTreeRegressor(random_state=0)\n",
    "dec_tree_reg.fit(X_train, y_train)\n",
    "y_pred = dec_tree_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 59.787028\n",
      "Mean squared error: 1270.900314\n",
      "r2 score: 0.999020\n"
     ]
    }
   ],
   "source": [
    "dec_tree_reg_ab_error = mean_absolute_error(y_test, y_pred)\n",
    "dec_tree_reg_sqrt_error = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# score = r2_score(y_test, y_pred)\n",
    "dec_tree_reg_r2_score = r2_score(y_test, y_pred)\n",
    "# dec_tree_reg_r2_score\n",
    "print(\"Mean absolute error: %2f\" % (dec_tree_reg_ab_error))\n",
    "print(\"Mean squared error: %2f\" % (dec_tree_reg_sqrt_error))\n",
    "print(\"r2 score: %2f\" % (dec_tree_reg_r2_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOM FOREST REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "random_forest_reg = RandomForestRegressor(random_state=0)\n",
    "random_forest_reg.fit(X_train, y_train.values)\n",
    "y_pred = random_forest_reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 259.327686\n",
      "Mean squared error: 2045.356980\n",
      "r2 score: 0.997460\n"
     ]
    }
   ],
   "source": [
    "# score = r2_score(y_test, y_pred)\n",
    "random_forest_reg_r2_score = r2_score(y_test, y_pred)\n",
    "# random_forest_reg_r2_score\n",
    "random_forest_reg_ab_error = mean_absolute_error(y_test, y_pred)\n",
    "random_forest_reg_sqrt_error = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"Mean absolute error: %2f\" % (random_forest_reg_ab_error))\n",
    "print(\"Mean squared error: %2f\" % (random_forest_reg_sqrt_error))\n",
    "print(\"r2 score: %2f\" % (random_forest_reg_r2_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHOW ACTUAL VALUES AND PREDICTED VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "actual values",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "predicted values",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "72cdd907-7bd6-4396-826e-ebe09e81d8b3",
       "rows": [
        [
         "8345",
         "120000.0",
         "120000.0"
        ],
        [
         "74986",
         "200000.0",
         "200000.0"
        ],
        [
         "73308",
         "28437.0",
         "28437.0"
        ],
        [
         "22896",
         "11169.0",
         "13410.18"
        ],
        [
         "71413",
         "105000.0",
         "105000.0"
        ],
        [
         "72258",
         "58167.0",
         "58167.0"
        ],
        [
         "79799",
         "69700.0",
         "69700.0"
        ],
        [
         "41254",
         "29730.0",
         "29730.0"
        ],
        [
         "55102",
         "99450.0",
         "99450.0"
        ],
        [
         "50102",
         "25944.0",
         "25944.0"
        ],
        [
         "29651",
         "150000.0",
         "149950.0"
        ],
        [
         "18728",
         "97000.0",
         "97000.0"
        ],
        [
         "46049",
         "50571.0",
         "50571.0"
        ],
        [
         "83192",
         "36324.0",
         "36324.0"
        ],
        [
         "76847",
         "140000.0",
         "140000.0"
        ],
        [
         "58969",
         "150000.0",
         "149850.0"
        ],
        [
         "50434",
         "100000.0",
         "100000.0"
        ],
        [
         "5824",
         "150000.0",
         "150000.0"
        ],
        [
         "33621",
         "58000.0",
         "58000.0"
        ],
        [
         "75607",
         "11867.0",
         "11867.0"
        ],
        [
         "63937",
         "38132.0",
         "38132.0"
        ],
        [
         "47475",
         "71093.0",
         "71093.0"
        ],
        [
         "53297",
         "10056.0",
         "10077.69"
        ],
        [
         "45107",
         "86478.0",
         "86542.86"
        ],
        [
         "63840",
         "145000.0",
         "144300.0"
        ],
        [
         "32460",
         "46024.0",
         "46024.0"
        ],
        [
         "52019",
         "72385.0",
         "72385.0"
        ],
        [
         "41254",
         "29730.0",
         "29730.0"
        ],
        [
         "69285",
         "95000.0",
         "92130.0"
        ],
        [
         "35858",
         "79993.0",
         "79993.0"
        ],
        [
         "18728",
         "97000.0",
         "97000.0"
        ],
        [
         "58088",
         "63337.0",
         "63337.0"
        ],
        [
         "66581",
         "100900.0",
         "100900.0"
        ],
        [
         "41950",
         "75669.0",
         "75669.0"
        ],
        [
         "76670",
         "49092.0",
         "49092.0"
        ],
        [
         "26648",
         "115000.0",
         "115000.0"
        ],
        [
         "6703",
         "50069.0",
         "50069.0"
        ],
        [
         "5110",
         "12144.0",
         "12144.0"
        ],
        [
         "17691",
         "20733.0",
         "20733.0"
        ],
        [
         "56405",
         "77556.0",
         "77556.0"
        ],
        [
         "47220",
         "85000.0",
         "85000.0"
        ],
        [
         "54817",
         "58368.0",
         "58368.0"
        ],
        [
         "9163",
         "54000.0",
         "54000.0"
        ],
        [
         "16131",
         "64630.0",
         "61359.0"
        ],
        [
         "55484",
         "37697.0",
         "37697.0"
        ],
        [
         "67372",
         "76831.0",
         "76831.0"
        ],
        [
         "33789",
         "36324.0",
         "36324.0"
        ],
        [
         "48905",
         "34591.0",
         "35001.78"
        ],
        [
         "33789",
         "36324.0",
         "36324.0"
        ],
        [
         "80337",
         "38916.0",
         "38916.0"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 1033
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual values</th>\n",
       "      <th>predicted values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8345</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>120000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74986</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>200000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73308</th>\n",
       "      <td>28437.0</td>\n",
       "      <td>28437.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22896</th>\n",
       "      <td>11169.0</td>\n",
       "      <td>13410.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71413</th>\n",
       "      <td>105000.0</td>\n",
       "      <td>105000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7129</th>\n",
       "      <td>78371.0</td>\n",
       "      <td>77955.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74305</th>\n",
       "      <td>88000.0</td>\n",
       "      <td>88000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56674</th>\n",
       "      <td>69800.0</td>\n",
       "      <td>69800.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71890</th>\n",
       "      <td>105000.0</td>\n",
       "      <td>105000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29040</th>\n",
       "      <td>174000.0</td>\n",
       "      <td>174000.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1033 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       actual values  predicted values\n",
       "8345        120000.0         120000.00\n",
       "74986       200000.0         200000.00\n",
       "73308        28437.0          28437.00\n",
       "22896        11169.0          13410.18\n",
       "71413       105000.0         105000.00\n",
       "...              ...               ...\n",
       "7129         78371.0          77955.20\n",
       "74305        88000.0          88000.00\n",
       "56674        69800.0          69800.00\n",
       "71890       105000.0         105000.00\n",
       "29040       174000.0         174000.00\n",
       "\n",
       "[1033 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_df= pd.DataFrame(data={\"actual values\" : y_test,\n",
    "                       \"predicted values\" : y_pred})\n",
    "check_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRID SEARCH CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "max_depth = [None, 2,4,6,8,10,12]\n",
    "parameters = {\"max_depth\": max_depth}\n",
    "\n",
    "regressor = DecisionTreeRegressor(random_state=0)\n",
    "gs = GridSearchCV(regressor, parameters, scoring='neg_mean_squared_error')\n",
    "gs.fit(X_train, y_train.values)\n",
    "regressor = gs.best_estimator_\n",
    "\n",
    "regressor.fit(X_train, y_train.values)\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 59.787028\n",
      "Mean squared error: 1270.900314\n",
      "r2 score: 0.999020\n"
     ]
    }
   ],
   "source": [
    "gs_ab_error = mean_absolute_error(y_test, y_pred)\n",
    "gs_sqrt_error = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "gs_score = r2_score(y_test, y_pred)\n",
    "print(\"Mean absolute error: %2f\" % (gs_ab_error))\n",
    "print(\"Mean squared error: %2f\" % (gs_sqrt_error))\n",
    "print(\"r2 score: %2f\" % (gs_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XG BOOST REGRESSOR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xg_reg = XGBRegressor()\n",
    "xg_reg.fit(X_train,y_train.values)\n",
    "y_pred = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 232.373495\n",
      "Mean squared error: 1614.796137\n",
      "r2 score: 0.998417\n"
     ]
    }
   ],
   "source": [
    "xg_reg_ab_error = mean_absolute_error(y_test, y_pred)\n",
    "xg_reg_sqrt_error = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "xg_reg_score = r2_score(y_test, y_pred)\n",
    "print(\"Mean absolute error: %2f\" % (xg_reg_ab_error))\n",
    "print(\"Mean squared error: %2f\" % (xg_reg_sqrt_error))\n",
    "print(\"r2 score: %2f\" % (xg_reg_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRADIENT BOOSTINB REGRESSOR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "grad_boost = GradientBoostingRegressor()\n",
    "grad_boost.fit(X_train, y_train.values)\n",
    "y_pred = grad_boost.predict(X_test)\n",
    "# r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 7346.468705\n",
      "Mean squared error: 11829.423658\n",
      "r2 score: 0.915054\n"
     ]
    }
   ],
   "source": [
    "grad_boost_ab_error = mean_absolute_error(y_test, y_pred)\n",
    "grad_boost_sqrt_error = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "grad_boost_score = r2_score(y_test, y_pred)\n",
    "print(\"Mean absolute error: %2f\" % (grad_boost_ab_error))\n",
    "print(\"Mean squared error: %2f\" % (grad_boost_sqrt_error))\n",
    "print(\"r2 score: %2f\" % (grad_boost_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPLORING TO PICKLE FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[\"United States of America\", 'Master’s degree', 15 , \"Man\" , \"Full Stack Developer\" , \"Small\" , \"11 - 17 years\" , \"Books\" , \"5\" , \"HTML/CSS\" , \"Microsoft SQL Server\" , \"AWS\" , \"Windows\"]])\n",
    "\n",
    "X[:, 0] = le_country.transform(X[:,0])\n",
    "X[:, 1] = le_education.transform(X[:,1])\n",
    "X[:, 3] = le_gender.transform(X[:,3])\n",
    "X[:, 4] = le_devtype.transform(X[:,4])\n",
    "X[:, 5] = le_orgsize.transform(X[:,5])\n",
    "X[:, 6] = le_Age1stCode.transform(X[:,6])\n",
    "X[:, 7] = le_LearnCode.transform(X[:,7])\n",
    "# X[:, 8] = le_YearsCode.transform(X[:,8])\n",
    "X[:, 9] = le_LanguageHaveWorkedWith.transform(X[:,9])\n",
    "X[:, 10] = le_DatabaseHaveWorkedWith.transform(X[:,10])\n",
    "X[:, 11] = le_PlatformHaveWorkedWith.transform(X[:,11])\n",
    "X[:, 12] = le_OpSys.transform(X[:,12])\n",
    "X = X.astype(float)\n",
    "# y_pred = regressor.predict(X)\n",
    "import pickle\n",
    "data = {\"model\": regressor, \"le_country\": le_country, \"le_education\": le_education , \"le_gender\": le_gender , \"le_devtype\": le_devtype , \"le_orgsize\" : le_orgsize , \"le_Age1stCode\":le_Age1stCode , \"le_LearnCode\" : le_LearnCode , \"le_YearsCode\":le_YearsCode , 'le_LanguageHaveWorkedWith' : le_LanguageHaveWorkedWith ,\n",
    "\"le_DatabaseHaveWorkedWith\":le_DatabaseHaveWorkedWith ,\n",
    "\"le_PlatformHaveWorkedWith\" : le_PlatformHaveWorkedWith ,\n",
    "\"le_OpSys\":le_OpSys\n",
    "        }\n",
    "with open('saved_steps.pkl', 'wb') as file:\n",
    "    pickle.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_steps.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Sample input\n",
    "X = np.array([[\n",
    "    \"United States of America\", 'Master’s degree', 15, \"Man\",\n",
    "    \"Full Stack Developer\", \"Small\", \"11 - 17 years\", \"Books\", \"5\",\n",
    "    \"HTML/CSS\", \"Microsoft SQL Server\", \"AWS\", \"Windows\"\n",
    "]])\n",
    "\n",
    "# Encode the inputs\n",
    "X[:, 0] = le_country.transform(X[:, 0])\n",
    "X[:, 1] = le_education.transform(X[:, 1])\n",
    "X[:, 3] = le_gender.transform(X[:, 3])\n",
    "X[:, 4] = le_devtype.transform(X[:, 4])\n",
    "X[:, 5] = le_orgsize.transform(X[:, 5])\n",
    "X[:, 6] = le_Age1stCode.transform(X[:, 6])\n",
    "X[:, 7] = le_LearnCode.transform(X[:, 7])\n",
    "# X[:, 8] = le_YearsCode.transform(X[:, 8])  # Skipped as in your original code\n",
    "X[:, 9] = le_LanguageHaveWorkedWith.transform(X[:, 9])\n",
    "X[:, 10] = le_DatabaseHaveWorkedWith.transform(X[:, 10])\n",
    "X[:, 11] = le_PlatformHaveWorkedWith.transform(X[:, 11])\n",
    "X[:, 12] = le_OpSys.transform(X[:, 12])\n",
    "\n",
    "X = X.astype(float)\n",
    "\n",
    "# Save the model and encoders using joblib\n",
    "data = {\n",
    "    \"model\": regressor,\n",
    "    \"le_country\": le_country,\n",
    "    \"le_education\": le_education,\n",
    "    \"le_gender\": le_gender,\n",
    "    \"le_devtype\": le_devtype,\n",
    "    \"le_orgsize\": le_orgsize,\n",
    "    \"le_Age1stCode\": le_Age1stCode,\n",
    "    \"le_LearnCode\": le_LearnCode,\n",
    "    \"le_YearsCode\": le_YearsCode,\n",
    "    \"le_LanguageHaveWorkedWith\": le_LanguageHaveWorkedWith,\n",
    "    \"le_DatabaseHaveWorkedWith\": le_DatabaseHaveWorkedWith,\n",
    "    \"le_PlatformHaveWorkedWith\": le_PlatformHaveWorkedWith,\n",
    "    \"le_OpSys\": le_OpSys\n",
    "}\n",
    "\n",
    "joblib.dump(data, 'saved_steps.joblib')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
